[{"content":"SAFA is a web interface for an eSports FIFA tournament service that was operating in Discord through a Discord bot. The goal was to expand the service to the web. The service hosts FIFA tournaments where users can register as players, create teams, and participate in tournaments. It is integrated with Discord for user authentication and provides features such as team creation and joining, player/team/league profiles with detailed stats and role-based views through public searching, and team management for managers.\nFeatures User Authentication: Users can login with their Discord account to access the service. Team Creation and Joining: Users can create teams and join teams. Player/Team/League Profiles: Detailed profiles with stats and role-based views. Team Management: Managers can manage teams and players. Search: Public searching for players, teams, and leagues. Gallery\nImplementation Authentication: Discord OAuth for user authentication using JWT and cookies. Backend: Three layered architecture (controller, service, DAO) with Express and Sequelize. Redis for caching and session management. Challenges Rate Limiting: Discord API has strict rate-limits for some endpoints. I used fetching with cache fallback using Redis to handle this. Concurrent Refresh Requests: In session management, multiple requests to refresh the access-token was causing issues. I handled this by using Redis as a mutex lock manager. Mistakes and Learnings Development environment flexibility: When testing features, at frontend I often needed to change my configurations like player ID, team ID, isManager, etc. which I initially hardcoded in the frontend code instead of conditionally using environment variables based on the environment (development/production). This made it difficult to test and debug. Backend software architecture: I initially started developing the backend with a monolithic architecture which made it difficult to extend and maintain. I later refactored it to a three-layered architecture which made it easier to manage and extend. Testing: I didn\u0026rsquo;t write tests for the frontend and backend. This made it difficult to refactor and add new features which taught me the importance of testing. Tech Stack Frontend: React, Tailwind CSS Backend: Node.js, Express, Redis, Sequelize ","permalink":"http://localhost:1313/projects/safa/","summary":"SAFA is a web platform for FIFA eSports tournaments, transitioning from a Discord bot to a full-fledged web interface with features like team management, stats tracking, and user authentication through Discord.","title":"SAFA"},{"content":"A Discord bot that serves as a general-purpose bot with various features aimed enhancing discord server management and engagement.\nFeatures Role Stats: Provides graphical statistics for user-defined role categories (e.g. age, region, etc.). User activity: Tracks messages sent by users and displays activity statistics. Bump Reminder: Reminds users to bump the server, tracks bump counts, and supports leaderboard. Invite Tracking: Tracks invites to the server and supports leaderboard. Server Lockdown and Backup Permissions: Allows server lockdown for backing up permissions. Supports Custom Prefixes Database ERD\rMotivationIn my discord server, many new comers after interacting with few people would wrongly assume the demographics of the server. I wanted to be able to view distribution of users based on roles like age, region, etc to be able to clear this up when anyone would mention it. However, I couldn\u0026rsquo;t find any bots that provided this feature. So, I decided to do it myself. Later, I noticed that there were other problems like bump reminders, invite tracking, etc. that either didn\u0026rsquo;t exist, were not customizable or were a paid feature in other bots. So, I developed my bot further to include these features.\nChallenges Database Design and Queries: I required a database to support the features I wanted to implement. However, I had no prior experience with databases. I had to learn about databases, design the database schema with normalization and relationships, and write queries to support the features I wanted to implement. Ethical Considerations: When I reached out for help with my bot, I was informed that while the features complied with Discord\u0026rsquo;s ToS, some of them raised concerns about user privacy and ethical considerations. I thought about making the bot transparent about what data it collects and how it uses it, like having the new users agree to a privacy policy to stay in the server. But it felt too much work and I left it there to be implemented later. Tech Stack PostgreSQL Python, Discord.py ","permalink":"http://localhost:1313/projects/abothasnoname/","summary":"A comprehensive Discord bot designed to enhance server management and engagement with unique features like role statistics, activity tracking, and invite monitoring.","title":"ABotHasNoName"},{"content":"A WebApp to schedule customizable round-robin sports tournaments. It\u0026rsquo;s a tool where users can input the playing teams and customize various parameters and constraints to generate and view round-robin tournament schedules. Check it out!\nSupported parameters number of teams number of matches each team plays against each other number of matches played on each day minimum gap of days (\u0026gt;= 0) between consecutive matches for any team minimum gap of matches (\u0026gt;= 0) between consecutive matches for any team starting date of tournament whether the schedule can allow days without any matches (we might want this to avoid deadlocks and obtain at least one schedule) whether schedule can allow consecutive matches involving the same two teams (we might want this to avoid deadlocks and obtain at least one schedule) number of permutations of schedules to output Produces permutations of schedules that is relative to each match while accounting for combinations of team pair ups within an individual match. For instance, it ensures that a match between Team A and Team B is not considered different from a match between Team B and Team A.\nSample\rMotivationWhen the IPL season began, my dad challenged me to create an algorithm to generate schedules similar to those of the IPL, with customizable parameters such as the number of teams, matches each team plays against each other, and more.\nSo, I got to work, using backtracking as the approach of which I had prior familiarity. It took me 2 days to develop and overcome challenges faced.\nChallenges Combination nature: Initially I was considering the schedules as permutations of matches including the team pair ups within a match. However, I realized that the schedules are actually permutations of combinations of team pair ups within a match. This increased the complexity of the algorithm. For instance, a match between Team A and Team B is not considered different from a match between Team B and Team A.\nDeadlocks: With some parameter configurations especially when the number of teams is small, it was not possible to produce schedules without leaving days without any matches or having consecutive matches involving the same two teams. I had to add parameters to allow these scenarios and handle them in the algorithm to avoid deadlocks and the algorithm running indefinitely.\nTime complexity: The algorithm has a time complexity of O(n!) where n is the number of teams. This is because the algorithm generates all permutations of schedules and then filters out invalid schedules. This means that the algorithm is not scalable for large number of teams and the systems I tested on had a limit of 8 teams it could handle. However, as my goal was to generate all possible schedules, I was okay with this limitation.\nTech Stack Frontend: React, Bootstrap Backend: Spring Boot Deployment: GitHub Pages for frontend, Render for backend with Docker ","permalink":"http://localhost:1313/projects/tournament-scheduler/","summary":"A web application to create customizable round-robin sports tournament schedules with user-defined parameters and constraints.","title":"Tournament Scheduler"},{"content":"You are familiar with using browsers to access websites and have seen URLs of website domains starting with http:// or https://, where when you type a URL like http://example.com in your browser\u0026rsquo;s address bar and press Enter, you are then presented with the website. How does this happen?\nFirst, where does the browser get this webpage document from? From a Web-Server. Which Web-Server? The one whose IP-Address is associated with the domain name example.com which is resolved by the DNS, say for example 1.1.1.1.\nNow, the browser just can\u0026rsquo;t ask \u0026lsquo;Hey 1.1.1.1, I want something\u0026rsquo;, it needs to be able to ask in a way that the Web-Server understands. This is where the HTTP Protocol comes into picture.\nWhat is HTTP?HTTP stands for HyperText Transfer Protocol. It is a communication protocol that uses client-server model with request-response protocol that is designed to transfer data between networked devices.\nIt is the foundation of data communication on the World Wide Web which allows browsers to retrieve webpages and other components from web-servers.\nIt is one of the Application Layer Protocols in TCP/IP, which means it is responsible for the communication between software applications on the network.\nSo basically, HTTP is the language that the client and server use to exchange web components over the internet.\nHow Does HTTP Work?HTTP works in a client-server model.\nFirst, the client sends a request to the server. Let\u0026rsquo;s look at how this request looks:\nRequest Line: Contains the method, the URL, and the HTTP version. The method specifies the action to be performed on the resource (GET, POST, PUT, DELETE, etc.). The URL specifies the location of the resource. The HTTP version specifies the version of the HTTP protocol being used. Headers: Contains additional information about the request like the type of content the client can accept (text/HTML, application/JSON, etc.), the type of content the client is sending (application/x-www-form-urlencoded, multipart/form-data, etc.), the type of encoding used (gzip, deflate, etc.), and more. Body: Contains the data being sent to the server. This is optional and is used in POST, PUT and PATCH requests. Next, the server processes the request and responds with the requested content. Let\u0026rsquo;s look at how this response looks:\nStatus Line: Contains the HTTP version, the status code (200 for success, 404 for not found, 500 for server error, etc.), and a status message. Headers: Contains additional information about the response like the type of content being sent (text/html, application/json, etc.), the length of the content, the type of encoding used (gzip, deflate, etc.), and more. Body: Contains the data being sent back to the client. This can be HTML content, JSON data, images, etc. One of the key features of HTTP is that it is a stateless protocol, which means each request is independent of the previous one. The server does not maintain any information about the client\u0026rsquo;s previous requests. To maintain state between requests, technologies like cookies and sessions are used.\nHTTP flow diagram\nIn this way, HTTP enables the client and server to communicate effectively over the internet.\nHTTP MethodsEvery HTTP request contains a method that specifies the action to be performed on the resource. Some common HTTP methods are:\nGET: Used to retrieve data from the server. Most webservers do not allow a request body, so the data is sent in the URL using path and query parameters. POST: Used for creating a new resource and to submit data to the server. The data is sent in the body of the request. A new resource is always created. PUT: Used for creating or replacing a resource on the server. The data is sent in the body of the request. If the resource already exists, it is replaced. DELETE: Used to delete data on the server. Like Get, most webservers do not allow a request body so the data is sent in the URL. PATCH: Used to partially update data on the server. The data is sent in the body of the request. HEAD: Similar to GET but only returns the headers. OPTIONS: Used to check what methods are allowed on a resource. HTTP Status CodesEvery HTTP response contains a status code that indicates the result of the request. Range of status codes are divided into 5 categories:\n1xx: Informational responses. Example: 100 Continue, 101 Switching Protocols. 2xx: Success responses. Example: 200 OK, 201 Created, 204 No Content. 3xx: Redirection responses. Example: 301 Moved Permanently, 302 Found, 304 Not Modified. 4xx: Client error responses. Example: 400 Bad Request, 401 Unauthorized, 404 Not Found. 5xx: Server error responses. Example: 500 Internal Server Error, 502 Bad Gateway, 503 Service Unavailable. These codes help developers and clients identify and handle the result of the request, enabling effective debugging.\nIdempotent MethodsSome HTTP methods are considered idempotent, which means that making the same request multiple times has the same effect as making it once. This property is useful in scenarios where requests can be retried without causing unintended side effects. Some idempotent methods are:\nGET: Retrieving data multiple times has the same effect. PUT: Replacing data multiple times has the same effect. DELETE: Deleting data multiple times has the same effect. HEAD: Retrieving headers multiple times has the same effect. OPTIONS: Checking allowed methods multiple times has the same effect. Post and Patch methods are not idempotent as making the same request multiple times can have different effects such as creating multiple resources or updating the resource multiple times.\nHTTP VersionsHTTP has evolved over the years, with different versions introducing new features and improvements. Some of the major versions are:\nHTTP/0.9: The first version of HTTP, introduced in 1991. It was a simple protocol that allowed clients to request a single file from a server. HTTP/1.0: Introduced in 1996, it added support for multiple types of data, including images, audio, and video. It also introduced status codes and headers. HTTP/1.1: Introduced in 1999, it is the most widely used version of HTTP. It introduced persistent connections, pipelining, and improved caching. HTTP/2: Introduced in 2015, it is a major revision of the HTTP protocol. It introduced features like multiplexing, header compression, and server push to improve performance. HTTP/3: Introduced in 2020, it is the latest version of HTTP. It is based on the QUIC protocol and aims to improve performance and security. Each version of HTTP builds on the previous one, adding new features and improvements to make the protocol more efficient and secure.\nHTTPSHTTP is a text-based protocol, which means that data sent over HTTP requests and responses is not encrypted. This allows anyone who intercepts the data to be able to read it easily as plain text.\nConsider the scenarios where you are logging into your bank account over an unencrypted HTTP connection. If someone intercepts the data, they can read your username and password, compromising your account. Or when you are entering your credit card details on an e-commerce website, if the HTTP connection is not encrypted, your credit card information can be stolen.\nTo address this security concern, HTTPS was introduced. HTTPS stands for HyperText Transfer Protocol Secure. It is the secure version of HTTP that encrypts the data sent between the client and server, making it difficult for attackers to intercept and read the data. HTTPS uses the TLS/SSL protocol to encrypt the data, ensuring that sensitive information like passwords, credit card details, and personal information is protected.\nWhen you visit a website that uses HTTPS, you will see a padlock icon in the address bar of your browser, indicating that the connection is secure. It is important to use HTTPS on websites that handle sensitive information to protect user data from interception and theft.\nConclusionHTTP/S is the backbone of the internet, enabling communication between clients and servers. Understanding how HTTP works, its methods, status codes, versions, and security features is essential for web developers to build secure and efficient web applications. By following the principles of HTTP, developers can create fast, reliable, and secure web experiences for users around the world.\n","permalink":"http://localhost:1313/blogs/what-are-http-and-https-protocols/","summary":"An in-depth look at what the HTTP protocol is, how it works, its methods, status codes, versions, and security features. Learn how HTTP enables communication between clients and servers over the internet.","title":"What are HTTP and HTTPS Protocols?"},{"content":"When you visit a website, you might have noticed a message that says, \u0026ldquo;This website uses cookies to ensure you get the best experience on our website\u0026rdquo; or have received a prompt to accept cookies. Before understanding what these cookies are and why they are used, let us look at the context around cookies.\nWhy Cookies?Browsers use the HTTP protocol to communicate with a web-server for requesting webpages, images, videos, and other resources. HTTP is a stateless protocol, meaning that each request is independent of the previous one, and the server does not maintain any information about your previous interactions with the website. However, websites often need to remember user-specific information to provide a personalized experience like remembering your login status, preferences, shopping cart items, and more.\nThere are few options for storing data on the client (browser) like:\nCookies: Small pieces of data. Local Storage: A larger storage area. Session Storage: A storage area that stores data for the duration of the page session. What Are Cookies?Cookies are small pieces of data stored on your browser by websites you visit. They have a name and a value, and can also have additional attributes. They are used to store user-specific information like login status, preferences, shopping cart items, and more.\nWhy/When to use Cookies over Local/Session Storage?Cookies provide the following advantages over Local/Session Storage:\nCookies are sent with every request: Every time you make a request to a website including ajax-requests, cookies are sent along automatically, providing server side accessibility. This is not the case with Local/Session Storage. Expiration and Path: Cookies can have an expiration date and a path, allowing them to be stored for a specific duration and accessed only on specific paths. Local/Session Storage either persists forever (Local Storage) or is cleared when the page session ends (Session Storage). Security: Cookies can have attributes that enhances security whereas Local/Session Storage does not have these security features. How Do Cookies Work?When you visit a website, the server sends a response to your browser with the web page document and a set of instructions to create cookies. Your browser creates and stores these cookies and sends them back to the server with every subsequent request (given the cookie\u0026rsquo;s path matches the request path) you make to the website.\nNote: In the case when a website uses different domains for its frontend and backend, cookies are likely not stored by the frontend domain (the website you visit), but by the backend domain.\nThus every cookie is associated with only one domain which is the the domain of the web server that set the cookie.\nAs Cookies are associated with a specific domain and path on the website, cookies created by one website cannot be accessed by another website. For example, cookies created by example.com cannot be accessed by anotherexample.com.\nNote: If the frontend and backend are on different domains, and the backend sets a cookie, the frontend cannot access it through document.cookie as it is on a different domain.\nCookie flow diagram\nWhy Are Cookies Used?Cookies serve several purposes on the web:\nSession Management: Cookies are used to manage user sessions on websites. They help websites remember your login status, shopping cart items, and other session-related information.\nTracking and Analytics: Cookies are used for tracking user behavior on websites. They help website owners understand how users interact with their site, which pages are popular, and more.\nAdvertising: Cookies are used for targeted advertising. They help advertisers show relevant ads to users based on their browsing history and interests.\nCookie AttributesCookies can have several attributes that define their behavior:\nName and Value: The name and value of the cookie.\nDomain: The domain or sub-domains associated with the cookie. The cookie is sent only to these sub/domain on subsequent requests.\nPath: The path on the website where the cookie is valid. The cookie is accessible and sent only for requests that match this path.\nExpiration Date: The date and time when the cookie expires. After this time, the cookie is no longer sent to the server and is deleted.\nSecure: A flag that indicates that the cookie should only be sent over secure connections (HTTPS). This ensures that the cookie values sent over the network are encrypted and not readable by unauthorized parties.\nHttpOnly: A flag that indicates the cookie should not be accessible by JavaScript (document.cookie) on the client-side. This helps to prevent XSS attacks from accessing sensitive cookies.\nSameSite: A flag that controls whether or not a cookie is sent with cross-site requests cross-site requests. It helps prevent CSRF attacks from making users unknowingly perform unwanted actions on other websites.\nManaging CookiesMost modern browsers allow you to manage cookies through their settings. You can view the cookies stored on your browser, delete specific cookies, block all cookies, or block cookies from specific websites.\nBy managing cookies, you can control your privacy and security while browsing the web. However, blocking all cookies may affect the functionality of some websites that rely on cookies for essential features.\nConclusionCookies are an essential part of the web ecosystem, allowing websites to remember user-specific information and provide a personalized experience. They are used for session management, personalization, tracking, advertising, and more. By understanding how cookies work and their attributes, you can make informed decisions about your privacy and security while browsing the web.\n","permalink":"http://localhost:1313/blogs/what-are-browser-http-cookies/","summary":"An in-depth look at what browser HTTP cookies are, why they are used, how they work, and their attributes. Learn how cookies are used for session management, personalization, tracking, and advertising on the web.","title":"What Are Browser HTTP Cookies?"},{"content":"\rWhy OAuth?Before we dive into OAuth, let\u0026rsquo;s understand why it is essential in the context of security. Every tool that humans create is done for fixing a problem, and OAuth is no different.\nLet us consider a scenario where you have stored your media files (images, videos, etc.) on a cloud storage service like Google Drive. Now, you are using a media editing application and want to edit an image/video that is stored on your Google Drive. You don\u0026rsquo;t want to download the file to your local system, edit it with the editing application, and then upload it back to Google Drive, because you find it inconvenient. Instead, you want the media editing application to directly access the file on Google Drive and make the necessary changes.\nSo, how do we get the media editing application to access your files on Google Drive? The files are in your Drive account and can only be accessed by you. One way is to provide your Google Drive credentials (username and password) to the media editing application. But this is a security risk because the application can misuse your credentials or store them insecurely. This is where OAuth comes into play. It provides a secure way for you to grant the media editing application access to your Google Drive files without sharing your credentials.\nIn this way, OAuth enables communication between different primary and third-party services while maintaining the security and privacy of user data.\n2.0? Are there different versions of OAuth?In this article, we will focus on OAuth 2.0, which is the latest version of OAuth. Other versions are OAuth 1.0 and OAuth 1.0a, which are now considered outdated due to security vulnerabilities and limitations.\nDefinitionOAuth (Open Authorization) is an open-standard for access delegation that allows a user to grant a third-party application access to their account/application\u0026rsquo;s resources or perform actions on behalf of them without them having to sharing their credentials to the third-party application.\nUse Cases of OAuth 2.0OAuth 2.0 is widely used in various scenarios to grant access to user data securely. Some common use cases of OAuth 2.0 include:\nSocial Login and Single Sign On: Social login is facilitated using OpenID Connect, an identity layer built on top of OAuth 2.0. This allows users to log in to applications using their social media accounts, such as Google, Facebook, or Twitter (e.g., \u0026ldquo;Log in with Google\u0026rdquo; or \u0026ldquo;Log in with Facebook\u0026rdquo; buttons). By handling authentication through these social media accounts, users need not create a new account and remember another set of credentials, enabling Single-Sign-On. It also lifts the burden of password management and security from the application owner. Third-Party Data Access: As mentioned, third-Party applications including plugins/extensions can access user data securely. Components of OAuth 2.0 Resource Owner: The user who owns the data and grants access to it. In the Google Drive example, you are the resource owner. Client: The third-party application that wants to access the user\u0026rsquo;s data. In the Google Drive example, the media editing application is the client. Authorization Server: The server that authorizes the client to access the user\u0026rsquo;s data. In the Google Drive example, Google\u0026rsquo;s authorization server. Resource Server: The server that hosts the user\u0026rsquo;s data. In the Google Drive example, Google Drive itself. How OAuth 2.0 WorksIf the users don\u0026rsquo;t share their credentials, how does OAuth 2.0 work? Through Access Tokens.\nAccess Tokens are like keys that allow the client to access the user\u0026rsquo;s data without knowing the user\u0026rsquo;s credentials. As they are short-lived, the authorization server may issue another key called the Refresh-Token to get a new Access Token when the current one expires without requiring the user to log in again.\nOAuth 2.0 works by following a series of steps to grant access to the user\u0026rsquo;s data:\nAuthorization Request: The client sends an authorization request to the authorization server, asking for permission to access the user\u0026rsquo;s data. The set of permissions requested is known as a \u0026ldquo;scope\u0026rdquo; (e.g., read access, write access, delete access).\nExample: \u0026ldquo;Can I access to reading and writing this user\u0026rsquo;s Google Drive files?\u0026rdquo; User Authentication and Authorization: The authorization server prompts the user to authorize the client to access their data. The user if not already logged in, authenticate themselves and grants the requested permissions. Upon granting permission, the client receives an authorization code.\nExample: You log in to your Google account and authorize the media editing application to access your Google Drive files. Note: You should always check the scope of permissions requested before granting access.\nAccess Token Request: The client exchanges the authorization code for an Access Token by sending a request to the authorization server.\nExample: The media editing application requests an Access Token to access your Google Drive files. Access Token Grant: The authorization server issues an Access Token to the client.\nExample: Google Drive issues an Access Token to the media editing application. Request Resource: The client sends the Access Token to the resource server to access the user\u0026rsquo;s data.\nExample: The media editing application uses the Access Token to access your Google Drive files. Resource Access: The resource server verifies the Access Token and grants access to the user\u0026rsquo;s data.\nExample: Google Drive verifies the Access Token and allows the media editing application to access your files. OAuth flow diagram\nConclusionOAuth 2.0 is a secure protocol that allows users to grant access to their data without sharing their credentials. It is widely used in various applications and scenarios to provide a secure and flexible way to access user data. Understanding OAuth 2.0 is essential for developers who want to build secure and user-friendly applications that interact with third-party services.\n","permalink":"http://localhost:1313/blogs/what-is-oauth-2_0-definition-use-cases-and-how-it-works/","summary":"A comprehensive guide to understanding OAuth (2.0), its definition, use cases, and how it works to grant secure access to user data.","title":"What Is OAuth (2.0)? | Definition, Use Cases, and How it Works"},{"content":"\rBackgroundI was tasked with extending an e-sports FIFA tournament service (SAFA) that had been operating primarily on Discord through a Discord bot, to the web. Since the database for users was modeled around their Discord account ID, the aim was to develop a web interface by integrating it with Discord. Thus I implemented login functionality using Discord OAuth.\nSession Management WorkflowInitially, the user is logged out. When the user logs in with their discord account, an access-token and refresh-token is created, both stored as JWTs in cookies. The access token is sent with all requests via the bearer authorization header for authentication and authorization purposes, while the refresh token is only sent to a specific refresh endpoint (/refresh). The backend verifies these tokens (JWT verification) whenever frontend (website) makes a request to it.\nIf verification fails for reasons other than token expiration (missing token, invalid token signature), the user is logged out. If the token has expired, the frontend silently attempts to refresh it by sending an additional request to backend at /refresh. If the refresh is successful, new access and refresh tokens are issued, and the original request is retried. If any error occurs during this process, including token expiry, the user is logged out.\nThe ProblemThis process works well when only one request is sent at a time. However, since the website uses client-side-rendering and is a single-page-application built with React, the web app often sends multiple ajax-requests simultaneously. This can lead to unintended session termination due to concurrent refresh attempts which logs the user out.\nWhy does this happen?When the access token has expired, the first request to the backend triggers a refresh and retrieves new tokens. However, before these new tokens are updated in the frontend, other requests are sent with the old tokens. If those requests also try to refresh the tokens, Discord returns an error (403) because the refresh token has already been used. This causes the system to terminate the user\u0026rsquo;s session thereby logging them out.\nSolution Options Extend token expiration time: This reduces the frequency of refreshes and unintended session terminations, but it introduces security risks and is not a proper solution. Queue requests: We queue all the requests, or we queue requests until the refresh is completed when frontend detects (before making a request) that the token is expired. This can slow down the app, especially when expiration times are short. Locking mechanism of Refresh Token: The backend uses locks on Refresh Tokens, ensuring that only one refresh attempt for a Refresh Token is processed at a time. The Chosen Solution: Redis-based Locking MechanismI chose to implement a locking mechanism using Redis, a fast in-memory data store with built-in key expiry.\nWe allow the first request to refresh the token while the others wait for the result of the first request. Here’s how it works:\nThe backend returns Token expiration error for the first request and the frontend then sends a refresh request to the backend at /refresh. Two Redis keys are used: refresh_token_lock:\u0026lt;Refresh Token\u0026gt;: Indicates whether the refresh token is being processed. refresh_token_res:\u0026lt;Refresh Token\u0026gt;: Holds the result status of the refresh attempt for the Token. At /refresh, backend first checks if a refresh_token_res:\u0026lt;Refresh Token\u0026gt; key exists in Redis. If it does, the system returns the corresponding result status. If the key does not exist, we check for the refresh_token_lock:\u0026lt;Refresh Token\u0026gt; key to see if another request has acquired the lock and is already processing the refresh token. If the lock is held, the request waits for it to be released and repeats previous step. If no lock is present, the request acquires the lock, performs the refresh, and sets the appropriate status key in Redis. The lock is then released, and the status is returned. Solution flowchart diagram\nThis ensures that only the first request refreshes the token, while other requests wait for the result.\nConclusionThe Redis-based locking mechanism effectively handles and prevents concurrent refresh attempts, and ensures that only one request is allowed to refresh tokens at a time. This solution enhances the overall reliability and security of token management in the system.\n","permalink":"http://localhost:1313/blogs/overcoming-concurrent-refresh-attempts-of-access-tokens-jwt/","summary":"A deep dive into handling concurrent refresh attempts of access tokens in a single-page application using JWT, OAuth, and Redis-based locking mechanisms to enhance token management security.","title":"Overcoming Concurrent Refresh Attempts of Access Tokens (JWT)"},{"content":"\rBackgroundI was tasked with developing a web interface for an e-sports FIFA tournament service (SAFA) that had been operating primarily on Discord through a Discord Bot. They wanted to extend their services to a website, and I was responsible for making it happen.\nAfter a new user joins their Discord server, before they can interact further (e.g., searching/joining teams), they are required to update their profile using a form. After which, they were given the roles \u0026ldquo;updated-profile\u0026rdquo; and \u0026ldquo;free-agent\u0026rdquo; (indicates not being present in any team). A player if present in a team has the role \u0026ldquo;player\u0026rdquo;.\nThe Problem: API Rate-LimitsWhenever a user registers or logs into the website using Discord OAuth, the dashboard view presented to them is based on their roles within the Discord server. The roles dictate what actions the user can take:\nIs the user part of the Discord server? (If not, prompt them to join) Has the user updated their profile? (If not, show the form) Is the user a \u0026ldquo;free-agent\u0026rdquo;? (If yes, provide options to join/create a team) Is the user a \u0026ldquo;team manager\u0026rdquo;? (If yes, provide team management options) These role details are fetched from the Discord API. However, the API has strict rate-limits: 5 requests per minute, with a soft reset allowing 1 request per minute after. The rate limit applies to a specific Access-Token for a Discord server.\nSince user roles can change based on user interactions through their existing Discord Bot (e.g., joining the server, updating profile, joining a team), we needed to re-fetch roles each time the browser tab was re-focused or reloaded. Additionally, in a React development environment with StrictMode enabled, each component renders twice which doubled the number of API requests. This often led to rate-limiting issues.\nThe Solution OptionsThere were two main approaches to handle this issue:\nMaintain Internal User Data: This option would involve using WebSockets with the bot to track user role changes in real-time and storing this data in a database. While this would ensure up-to-date information, it introduces significant complexity and resource overhead.\nCache Fetched Data from the Discord API: This simpler solution involves caching user roles from the Discord API where we use the cached data if the API is rate-limited. The trade-off is a delay in real-time data (maximum of 1 minute), but this was acceptable for our use case.\nWe opted for the caching approach using Redis, as it provides both efficiency and native data expiry.\nThe Solution: Fetch with Cache FallbackWe implemented a fetch-with-cache fallback mechanism. Here’s how it works:\n1. Check for Rate-Limit KeyBefore making an API call, we check if we’ve been currently rate-limited by looking for a Redis key of the pattern discord_roles_\u0026lt;ServerID\u0026gt;_\u0026lt;AccessToken\u0026gt;_retry-after. This key is created when a previous request was rate-limited.\n2. Handle Rate-Limited RequestsIf this rate-limit key exists, we don’t attempt to make a new API call. Instead, we return the cached data stored in Redis with the key of pattern discord_roles_\u0026lt;ServerID\u0026gt;_\u0026lt;UserID\u0026gt;.\n3. Make API RequestIf the rate-limit key isn’t found, we proceed to fetch the user’s roles from the Discord API.\nIf the request is successful, we cache the data with a key of the pattern discord_roles_\u0026lt;ServerID\u0026gt;_\u0026lt;UserID\u0026gt; and return it. If the request receives a rate-limit error, we create the key discord_roles_\u0026lt;ServerID\u0026gt;_\u0026lt;AccessToken\u0026gt;_retry-after with an expiry set to the rate-limit reset time (plus 1 second). After this, we return the previously cached data. Solution flowchart diagram\nWhat I Learned and Future ConsiderationsWhile this solution worked well for our use case, I realized that using Redis opened up more possibilities for handling similar challenges elsewhere in the project. For instance, I later used Redis to solve another issue related to concurrent refresh attempts of access tokens.\nIn retrospect, there is another approach we could consider for future versions. Partial WebSocket Implementation: Given the requirement for very specific role updates, partial WebSocket integration in the website with Discord Gateway API could help fetch only critical updates in real-time without introducing unnecessary overhead.\nConclusionA simple fetch-with-cache fallback system using Redis allowed us to deliver a smooth user experience while adhering to Discord’s API constraints. The combination of simplicity and effectiveness made Redis a good fit for this project.\n","permalink":"http://localhost:1313/blogs/overcoming-discord-api-rate-limits-with-redis-cache/","summary":"How to handle (Discord) API rate limits using a Redis-based caching mechanism in a web application.","title":"Overcoming (discord) API Rate Limits With Redis Cache"}]